<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>bb - FGM and the cost of complexity</title>
        <link rel="stylesheet" href="../css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../"><i>bb</i></a>
            </div>
            <nav>
                <a href="../">home</a>
                <a href="../about.html">about</a>
                <a href="../other.html">other</a>
            </nav>
        </header>

        <main role="main">
            <article>
    <section class="header">
        Posted on January  1, 2021
        
    </section>
    <section>
        <h1 id="fishers-geometric-model-and-the-cost-of-complexity">Fisher’s geometric model and the cost of complexity</h1>
<p><em>The following is based on a polishing of some notes I made for a
presentation on H. A. Orr’s paper “Adaptation and the cost of complexity”
<span class="citation" data-cites="orr2000">[@orr2000]</span> for our reading group on ‘concepts and models in evolution’ at
Ghent University (January 2021).</em></p>
<p>I will start by discussing some of the basics of Fisher’s Geometric model
(FGM). Then I will switch to Orr’s paper. What Orr is after is a model of
adaptation at the phenotypic level that is grounded in population
genetics, with phenotypic complexity <em>as a parameter</em>. To this end, he
builds on the work of <span class="citation" data-cites="kimura1983">@kimura1983</span>, which makes the connection between FGM
and the population genetics of selection.</p>
<h2 id="fishers-geometric-model-fgm">Fisher’s geometric model (FGM)</h2>
<p>In the section “The nature of adaptation” (p. 38) of <span class="citation" data-cites="fisher1930">@fisher1930</span>, Fisher asks
what we mean when we recognize an organism as adapted.</p>
<blockquote>
<p>“In order to consider in outline the consequences to the organic world
of the progressive increase of fitness of each species of organism, it is
necessary to consider the abstract nature of the relationship which we term
‘adaptation’. This is the more necessary since any <em>simple</em> example of
adaptation, such as the lengthened neck and legs of the giraffe as an
adaptation to browsing on high levels of foliage, or the conformity in average
tint of an animal to its natural background, lose, by the very simplicity of
statement, a great part of the meaning which the word really conveys. For the
more complex the adaptation, the more numerous the different features of
conformity, the more essentially adaptive the situation is recognized to be.”</p>
</blockquote>
<p>Clearly, when we think of adaptation, we are tempted to consider those obvious
examples like the giraffe (<a href="https://en.wikipedia.org/wiki/Giraffe#Neck">or is
it?</a>), but as Fisher wants to stress
in this opening paragraph, this is misguiding us. Most of the extraordinary
adaptation in nature can not be recognized as a simple one-to-one
correspondence between an environmental challenge and a phenotype, but is
rather reflected by the subtle fine-tuning of complex organisms to complex
environments. The ability to maintain homeostasis in a given array of
conditions seems to be the ultimate example of such a phenotype. Already in
this opening paragraph, the correspondence between <em>complexity</em> and
<em>dimensionality</em> is explicitly posited.</p>
<blockquote>
<p>“The statistical requirements of the situation, in which one thing is to
conform to another in a large number of different respects, may be illustrated
geometrically. The degree of conformity may be represented by the closeness
with which a point <span class="math inline">\(A\)</span> approaches a fixed point <span class="math inline">\(O\)</span>. In a space of <strong>three
dimensions</strong> we can only represent conformity in three different respects, but
even with only these the general character of the situation may be represented.
The possible positions representing adaptations superior to that represented by
<span class="math inline">\(A\)</span> will be enclosed by a sphere passing through <span class="math inline">\(A\)</span> and centred at <span class="math inline">\(O\)</span>. If <span class="math inline">\(A\)</span>
is shifted through a fixed distance, <span class="math inline">\(r\)</span>, in any direction its translation will
improve the adaptation if it is carried to a point within this sphere, but will
impair it if this position is outside. If <span class="math inline">\(r\)</span> is very small, it may be
perceived that the chances of these two events are approximately equal, and the
chance of an improvement tends to the limit <span class="math inline">\(1/2\)</span> as <span class="math inline">\(r\)</span> tends to zero; but if
<span class="math inline">\(r\)</span> is as great as the diameter of the sphere or greater, there is no longer
any chance whatever of improvement, for all points within the sphere are less
than this distance from <span class="math inline">\(A\)</span>. For any value of <span class="math inline">\(r\)</span> between these limits the
actual probability of improvement is <span class="math inline">\(\frac{1}{2}(1-r/d)\)</span> where <span class="math inline">\(d\)</span> is the
diameter of the sphere. The chance of improvement thus decreases steadily from
limiting value <span class="math inline">\(1/2\)</span> when <span class="math inline">\(r\)</span> is zero, to zero when <span class="math inline">\(r\)</span> equals <span class="math inline">\(d\)</span>. Since <span class="math inline">\(A\)</span>
in our representation may signify either the organism or its environment, we
should conclude that a change on either side has, when this change is extremely
minute, an almost equal chance of effecting improvement or the reverse; while
for greater changes the chance of improvement diminishes progressively,
becoming zero, or at least negligible, for changes of a sufficiently pronounced
character.” (emphasis mine)</p>
</blockquote>
<p>Here Fisher defines his famous geometric model in 3D. Let us however define
Fisher’s model in general first, then we’ll consider the 2D variant, to finally
generalize to the high-dimensional case.</p>
<p>FGM is a model of <em>phenotypic evolution</em>. A biological entity (this can be an
individual or a population), is modeled as a point <span class="math inline">\(A\)</span>, in an <span class="math inline">\(n\)</span>-dimensional
vector space <span class="math inline">\(\mathbb{R}^n\)</span> – the phenotypic space. The phenotypic space is
characterized by a single optimal phenotype, which we identify (without loss of
generality) with the origin of the space <span class="math inline">\(O\)</span>. That is, we choose the basis of
the vector space such that the optimum is the zero vector <span class="math inline">\(\mathbf{0}\)</span>, and
such that any phenotypic state <span class="math inline">\(A\)</span> in this space can be identified with the
vector <span class="math inline">\(z\)</span> pointing from the optimum to the relevant point. If we take this
vector space to be a normed Euclidean space, the distance from the optimum for
any given point <span class="math inline">\(z\)</span> is then the Euclidean norm <span class="math inline">\(\Vert z \Vert\)</span>. Clearly, this model
amounts to treating an organism as a list of <span class="math inline">\(n\)</span> orthogonal characters.</p>
<p>Those are the statics of the model, for any given two phenotypic states <span class="math inline">\(z_1\)</span>
and <span class="math inline">\(z_2\)</span>, we can say which one exhibits a higher degree of adaptation (i.e.
the one closest to the optimum, as measured by the Euclidean norm). Evolution
in the model happens by mutation, where a mutation takes the current phenotype
represented by point <span class="math inline">\(A\)</span> to a point <span class="math inline">\(A'\)</span> by moving a distance <span class="math inline">\(r\)</span> in a random
direction from the point <span class="math inline">\(A\)</span>. In other words, the phenotype after a random
mutation is distributed uniformly on the <span class="math inline">\(n\)</span>-ball (hypersphere) around <span class="math inline">\(A\)</span> with
radius <span class="math inline">\(r\)</span>. The mutation can be represented as a vector <span class="math inline">\(\rho\)</span> with
<span class="math inline">\(\Vert \rho \Vert = r\)</span>, so that the phenotype after mutation <span class="math inline">\(z' = z + \rho\)</span>. An
important assumption embodied by this mutation mechanism is what is referred to
as <strong>universal pleiotropy</strong>, i.e. every mutation affects <em>all</em> traits (the set
of vectors of zero magnitude in any direction has measure 0, i.e. a random
vector with norm <span class="math inline">\(r\)</span> in <span class="math inline">\(\mathbb{R}^n\)</span> is non-zero in every direction with
probability 1).</p>
<h3 id="fgm-in-two-dimensions">FGM in two dimensions</h3>
<p>Let’s see what we can get from considering this model in <span class="math inline">\(\mathbb{R}^2\)</span> by pondering
the following diagram</p>
<p><img src="../img/2021-01-01-fgm/fgm2d-2.png" style="width:100.0%" /></p>
<p>For a given mutation effect size <span class="math inline">\(r &lt; \Vert z \Vert\)</span> and current distance to the
optimum <span class="math inline">\(\Vert z \Vert\)</span>, the distance moved towards the optimum <span class="math inline">\(\Delta z\)</span> can be
expressed as a function of <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[\Delta z(\theta) = \Vert z \Vert - \sqrt{\Vert z \Vert^2 -2\Vert z \Vert r \cos \theta +
    \frac{r^2}{2}} \approx r \cos \theta - \frac{r^2}{2 \Vert z \Vert}\]</span></p>
<p>(<strong>Note</strong> I am not so sure what justifies the approximation of the former by the latter.
A Taylor series expansion in <span class="math inline">\(r = 0\)</span> seems to go some way, but not all the way
as far as I can tell). In <span class="math inline">\(\mathbb{R}^2\)</span>, the assumption that the mutation has a
random direction in the plane amounts to <span class="math inline">\(\theta \sim \mathrm{Uniform}(0,2\pi)\)</span>, so that we can find using the approximate form for
<span class="math inline">\(\Delta z\)</span>, we find that the probability of a mutation being adaptive is</p>
<p><span class="math display">\[P_a = \Pr\{\Delta z &gt; 0\} \approx 
    \Pr\{\theta &gt; \cos^{-1} r/2z\} = 1 - \frac{\cos^{-1} r/d}{2\pi}\]</span></p>
<h3 id="fgm-in-three-and-higher-dimensions">FGM in three and higher dimensions</h3>
<p>In higher dimensions, <span class="math inline">\(\Delta z(\theta)\)</span> remains unaltered, i.e. we still have
the triangle <span class="math inline">\(AA'O\)</span>, and we can still express the distance moved towards the
optimum as the same function of <span class="math inline">\(\theta\)</span>. However, <span class="math inline">\(\theta\)</span> will no longer be
uniformly distributed on <span class="math inline">\((0, 2\pi)\)</span>. For the 3D case, we can work it out using
the volume of the <a href="https://mathworld.wolfram.com/Sphere-SphereIntersection.html">spherical
lens</a> divided by
the volume of a sphere with radius <span class="math inline">\(r\)</span>, for which I get <span class="math inline">\(P_a = \frac{1}{2}\big(1 - \frac{3r}{4d}\big)\)</span> for the probability of improvement
(which is not exactly Fisher’s probability). Importantly, <span class="math inline">\(P_a\)</span> in <span class="math inline">\(\mathbb{R}^3\)</span> is
different from <span class="math inline">\(P_a\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span>.</p>
<p>However the question remains whether we can find an (approximate) expression for
<span class="math inline">\(P_a\)</span> in any dimension. Here is Fisher:</p>
<blockquote>
<p>“The representation in three dimensions is evidently inadequate for
even single organ, in cases in which we know enough to appreciate the relation
between structure and function, as is, broadly speaking, the case with the eye
in vertebrates, often shows this conformity in many more than three respects.
It is of interest therefore, that if in our geometrical problem the number of
dimensions be increased, the form of the relationship between the magnitude of
the change <span class="math inline">\(r\)</span> and the probability of improvement, tends to a limit […]”</p>
</blockquote>
<p>As <span class="citation" data-cites="leigh1987">@leigh1987</span> supposedly showed (I’m not sure, I cannot retrieve this paper),
the limit postulated (but not explicitly derived) by Fisher can be obtained by
considering the change of variables</p>
<p><span class="math display">\[y = \sqrt{n} \cos \theta\]</span></p>
<p>and noting that for <span class="math inline">\(n \gg\)</span>, we get that <span class="math inline">\(y\)</span> approximately follows a standard
Normal distribution. The derivation involves some nasty integrals (see e.g.
<span class="citation" data-cites="welch2003">@welch2003</span> appendix 1), but there are reasons why it is unsurprising to find
the Normal distribution here (the multivariate Normal distribution exhibits
spherical symmetry, i.e. the probability density is invariant to rotations, as
we assume for mutations in FGM). Here are some simulation results, where I
simulated random points on the Euclidean <span class="math inline">\(n\)</span>-ball and computed <span class="math inline">\(y\)</span>:</p>
<p><img src="../img/2021-01-01-fgm/yisnormal.png" /></p>
<p>Where in black the simulated values for <span class="math inline">\(y\)</span> are shown and in blue the standard
normal density. Starting from <span class="math inline">\(n \ge 10\)</span> the Normal approximation becomes very
good.</p>
<p>If we execute the change of variables, we get</p>
<p><span class="math display">\[\Delta z(y) \approx \frac{r}{\sqrt n} \Big(y - \frac{r\sqrt n}{2 \Vert z \Vert}\Big)\]</span></p>
<p>Which shows that given the current distance to the optimum <span class="math inline">\(\Vert z \Vert\)</span>, for a
mutation of given size <span class="math inline">\(r\)</span> to be adaptive <span class="math inline">\(y\)</span> must exceed <span class="math inline">\(x := \frac{r\sqrt{n}}{2 \Vert z \Vert}\)</span>, so that</p>
<p><span class="math display">\[P_a = 1 - \Phi(x)\]</span></p>
<p>Where <span class="math inline">\(\Phi(x)\)</span> is the cumulative distribution function of the standard Normal
density. of course <span class="math inline">\(1-\Phi(x)\)</span> is monotonically decreasing in <span class="math inline">\(x\)</span>, so we find
Fisher’s result that the probability that a mutation leads to improvement is
highest for infinitesimally small mutations, and declines progressively for
larger <span class="math inline">\(r\)</span>. Note that <span class="math inline">\(x &gt; 0\)</span>, so that the maximal <span class="math inline">\(P_a = 1/2\)</span>. Interestingly,
since <span class="math inline">\(x \propto \sqrt{n}\)</span>, we also find that this decline in the probability
of a mutation leading to adaptation decreases quite markedly with increasing
dimensionality <span class="math inline">\(n\)</span>, the parameter that corresponds to, on Fisher’s
interpretation, organismal complexity (and which, in a less bold
interpretation, corresponds to the number of orthogonal characters relevant for
adaptation). This is the first manifestation of the <strong>cost of complexity</strong>, for
mutations of a given size <span class="math inline">\(r\)</span> and given some degree of maladaptation
<span class="math inline">\(\Vert z \Vert\)</span>, the probability of a mutation being adaptive decreases with
increasing complexity <span class="math inline">\(n\)</span>.</p>
<p><img src="../img/2021-01-01-fgm/fisherpa.svg" /></p>
<p>This probability is the central result of FGM. This is actually [a reflection
of a very general geometrical phenomenon, namely that in <em>high-dimensional
spaces it is very hard to locate some point or region</em>. If you are situated at
some distance <span class="math inline">\(d\)</span> from a point <span class="math inline">\(O\)</span> in some <span class="math inline">\(n\)</span>-dimensional space, and you move
in a random direction by some distance <span class="math inline">\(r &lt; d\)</span>, the likelihood that you’ll get
closer to the point <span class="math inline">\(O\)</span> decreases exponentially as the dimensionality
increases. As a mathematician once put it: <a href="https://betanalpha.github.io/img/case_studies/probabilistic_computation.html">high-dimensional space is a lonely
place</a>.</p>
<h2 id="orrs-model-of-adaptation">Orr’s model of adaptation</h2>
<p>FGM as sketched above is not a complete model of evolution. In fact, it doesn’t
tell us much about how a population evolves, except that mutations of larger
effect are less likely to be advantageous in more ‘complex’ organisms.</p>
<p>To build a model of evolution under FGM, we need</p>
<ul>
<li>a mutation <em>process</em></li>
<li>a relationship between phenotype and fitness (a <em>fitness function</em>)</li>
</ul>
<p>So far we have only considered properties of FGM <em>given</em> some random FGM
mutation, but we have said nothing about how often mutations of a given effect
will occur during evolution. Moreover, and this is of crucial importance, if we
consider <span class="math inline">\(z\)</span>, the point in space moving towards the optimum, as a <em>population</em>
(as Orr does), we must take into account the probability that a mutation <em>fixes
in the population</em>, and leads to a persistent change in the mean phenotype <span class="math inline">\(z\)</span>.
This fixation probability will depend on the change in <em>fitness</em> caused by the
mutation.</p>
<p>We will consider Gaussian stabilizing selection, so that the fitness of an
individual with phenotype <span class="math inline">\(z\)</span> is given by</p>
<p><span class="math display">\[ w(z) = \exp (-\Vert z \Vert^2) \]</span></p>
<p>and we consider mutations of fixed size <span class="math inline">\(r\)</span> happening at a rate <span class="math inline">\(\mu\)</span> per
individual, so that the total mutation rate for a population of size <span class="math inline">\(N\)</span> is
<span class="math inline">\(N\mu\)</span>.</p>
<p>Now for some <strong>simplifying assumptions</strong>, Orr considers a monomorphic
population residing at a distance <span class="math inline">\(\Vert z \Vert\)</span> from the optimum, where every
mutation is either fixed or lost before the next one occurs (i.e. <span class="math inline">\(N\mu\)</span> is
fairly small). Orr further assumes that deleterious mutations are never fixed
by random drift.</p>
<p>Under this model, the <strong>expected distance moved to the optimum</strong> in a small
time interval will be</p>
<p><span class="math display">\[\mathbb{E}[\Delta z(\delta t)] = \mathbb{E}[\Delta z|\text{fix}] 
        \times \underbrace{P[\text{fix}|\text{adv}]}_{\Pi}
        \times \underbrace{P[\text{adv}|\text{mut in } \delta t]}_{P_a} 
        \times \underbrace{P[\text{mut in } \delta t]}_{(N\mu)\delta t}\]</span></p>
<p>So that <strong>the rate of phenotypic change</strong></p>
<p><span class="math display">\[\begin{aligned}
   \frac{d \Vert z(t) \Vert}{d t} &amp;= \lim_{\delta t \rightarrow 0}\frac{\Vert z(t + \delta t) \Vert- \Vert z(t) \Vert}{\delta t} \\
   &amp;\color{lightgray}{= \lim_{\delta t \rightarrow 0}
        \frac{(\Vert z(t) \Vert- \mathbb{E}[\Delta z(\delta t)]) - \Vert z(t) \Vert}{\delta t}} \\ 
   &amp;\color{lightgray}{= \lim_{\delta t \rightarrow 0}
        \frac{- \mathbb{E}[\Delta z(\delta t)]}{\delta t}} \\ 
   &amp;= -(N \mu) \times \Pi \times P_a \times \mathbb{E}[\Delta z|\text{fix}]
\end{aligned}\]</span></p>
<p>(note that this is in fact the rate of change of the <em>expected</em> distance to the
optimum <span class="math inline">\(d\mathbb{E}\Vert z(t) \Vert/dt\)</span> , but I will follow Orr in blurring this distinction).</p>
<p>If we measure time in the number of mutations produced, we get</p>
<p><span class="math display">\[ \frac{d \Vert z \Vert}{dt} = - \Pi \times P_a \times \mathbb{E}[\Delta z | \text{fix}] \]</span></p>
<p>We know <span class="math inline">\(P_a\)</span> from the properties of FGM discussed above. To make progress we
need to find <span class="math inline">\(\Pi\)</span> and <span class="math inline">\(\mathbb{E}[\Delta z | \text{fix}]\)</span> as functions of the
parameters in the model (which consists of nothing more than <span class="math inline">\(z\)</span>, <span class="math inline">\(r\)</span>, <span class="math inline">\(y = \sqrt{n} \cos \theta\)</span> and <span class="math inline">\(n\)</span>).</p>
<h3 id="the-probability-of-fixing-an-advantageous-mutation">The probability of fixing an advantageous mutation</h3>
<p><span class="math inline">\(\Pi\)</span> is given by fairly standard results from population genetics theory. The
probability of fixing an adaptive mutation is given by Haldane’s approximation
(also by diffusion theory) as <span class="math inline">\(2s\)</span> when <span class="math inline">\(s\)</span> is not too large, where <span class="math inline">\(s\)</span> is the
selection coefficient in favor of the mutation. The selection coefficient for a
mutation moving <span class="math inline">\(\Delta z\)</span> towards the optimum is defined as</p>
<p><span class="math display">\[ \frac{1+s}{1} = \frac{w(z - \Delta z)}{w(z)} \]</span></p>
<p>Now Orr considers Gaussian stabilizing selection, so that for a mutation that
moves us a distance <span class="math inline">\(\Delta z\)</span> towards the optimum, we get a selection coefficient</p>
<p><span class="math display">\[s = \frac{\exp(-\frac{1}{2}(\Vert z \Vert- \Delta z)^2/2)}{\exp(-\frac{1}{2}\Vert z \Vert^2)} - 1 = 
	\exp\Big(\Vert z \Vert\Delta z - \frac{\Delta z^2}{2}\Big) - 1\]</span></p>
<p>(note that there is a typo in Orr). For <span class="math inline">\(\Delta z\)</span> smallish we have</p>
<p><span class="math display">\[s \approx \exp(\Vert z \Vert\Delta z) - 1 \approx \Vert z \Vert\Delta z\]</span></p>
<p>The <em>expected</em> selection coefficient for advantageous mutations is then</p>
<p><span class="math display">\[\mathbb{E}[s|\text{adv}] \approx \Vert z \Vert\mathbb{E}[\Delta z | \text{adv}]\]</span></p>
<p>so that the fixation probability conditional on a mutation being advantageous
becomes becomes</p>
<p><span class="math display">\[\Pi \approx 2 \Vert z \Vert\mathbb{E}[\Delta z| \text{adv}]\]</span></p>
<p>Now we’ve obtained</p>
<p><span class="math display">\[ \frac{d \Vert z \Vert}{dt} = - 2  \Vert z \Vert\times P_a \times \mathbb{E}[\Delta z| \text{adv}]
\times \mathbb{E}[\Delta z | \text{fix}] \]</span></p>
<h3 id="the-expected-phenotypic-change-under-fgm">The expected phenotypic change under FGM</h3>
<p>Now the somewhat more tedious part is to find <span class="math inline">\(\mathbb{E}[\Delta z| \text{adv}]\)</span> and
<span class="math inline">\(\mathbb{E}[\Delta z| \text{fix}]\)</span>. These can be found from the properties of FGM.
<span class="math inline">\(\mathbb{E}[\Delta z| \text{adv}]\)</span> can be straightforwardly obtained by integrating
<span class="math inline">\(\Delta z\)</span> over advantageous mutations. For clarity of the probabilistic
aspects, I’ll write a mutation being advantageous as a binary random variable
<span class="math inline">\(A = \mathbb{1}_\text{adv}\)</span>, and probability density functions are denoted
by <span class="math inline">\(p(\cdot)\)</span></p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[\Delta z|A=1] &amp;= \int_{\Delta z} \Delta zp(\Delta z|A=1) d\Delta z\\
    &amp;= \frac{1}{P_a}\int_{\Delta z} \Delta zp(\Delta z, A=1) d\Delta z
\end{aligned}\]</span></p>
<p>Note that</p>
<p><span class="math display">\[p(\Delta z, A=1) = \begin{cases} 0 &amp; \Delta z&lt; 0 \\ p(\Delta z) &amp; \Delta z\ge 0\end{cases}\]</span></p>
<p>so that</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[\Delta z|A=1] &amp;= \frac{1}{P_a}\int_0^\infty \Delta zp(\Delta z) d\Delta z\\
    &amp;= \frac{r}{\sqrt{n}} \frac{\int_{x}^\infty (y - x) \exp(-y^2/2) dy}
        {\int_x^\infty \exp(-y^2/2)dy} 
\end{aligned}\]</span></p>
<p>(note that the denominator is <span class="math inline">\(\sqrt{2\pi} P_a\)</span>). Slightly more cumbersome is
the derivation of <span class="math inline">\(\mathbb{E}[\Delta z|F=1]\)</span> (where of course <span class="math inline">\(F = \mathbb{1}_\text{fix}\)</span>)</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[\Delta z|F = 1] = \mathbb{E}[\Delta z|F=1, A=1] 
    &amp;= \int_{\Delta z} \Delta z\frac{p(\Delta z, F=1|A=1)}{p(F=1|A=1)} d \Delta z\\
    &amp;= \int_{\Delta z} \Delta z\frac{p(F=1|\Delta z, A=1)p(\Delta z|A=1)}
        {\int_{\Delta z}p(\Delta z,F=1|A=1)p(\Delta z|A=1)} d \Delta z\\
    &amp;= \int_{\Delta z} \Bigg[ \frac{\Delta z\Pi(\Delta z) p(\Delta z|A=1)}
        {\int_{\Delta z}\Pi(\Delta z) p(\Delta z|A=1) d\Delta z} \Bigg] d\Delta z
\end{aligned}\]</span></p>
<p>Where (recall) <span class="math inline">\(\Pi(\Delta z) \approx 2 \Vert z \Vert\Delta z\)</span> for small <span class="math inline">\(\Delta z\)</span>. The integral in
the denominator is a normalizing constant, so that we get</p>
<p><span class="math display">\[\begin{aligned}
\mathbb{E}[\Delta z|F = 1] &amp;= \frac{\int_{\Delta z} \Delta z^2 p(\Delta z|A=1)d\Delta z}
        {\int_{\Delta z}\Delta zp(\Delta z|A=1)d\Delta z} \\ 
    &amp;= \frac{r}{\sqrt{n}} \frac{\int_{x}^\infty (y-x)^2 \exp(y^2/2) dy}
        {\int_x^\infty (y-x) \exp(y^2/2)dy}
\end{aligned}\]</span></p>
<p>and finally we get</p>
<p><span class="math display">\[\mathbb{E}[\Delta z|\text{adv}] E[\Delta z|\text{fix}] = \frac{r^2}{n}
	\frac{\int_x^\infty (y - x)^2 \exp(-y^2/2) dy}
         {\int_x^\infty \exp(-y^2/2)dy}\]</span></p>
<p>Let the mathematicians laugh at my lengthy and probably silly derivations, but there
are no more secrets here to me!</p>
<h3 id="the-rate-of-phenotypic-change-and-the-rate-of-adaptation">The rate of phenotypic change and the rate of adaptation</h3>
<p>We are now ready to express the rate of phenotypic change during adaptation in
terms of the parameters of FGM. Multiplying by <span class="math inline">\(-2\Vert z \Vert P_a\)</span>, we arrive at</p>
<p><span class="math display">\[\frac{d \Vert z(t) \Vert}{dt} \approx - \frac{2 \Vert z(t) \Vert r^2}{n\sqrt{2\pi}}
        \int_x^\infty (y - x)^2 \exp(-y^2/2) dy\]</span></p>
<p>where <span class="math inline">\(x = \frac{r\sqrt{n}}{2\Vert z(t) \Vert}\)</span>. We can write this more clearly as</p>
<p><span class="math display">\[\frac{d \Vert z(t) \Vert}{dt} \approx - \frac{2r^2}{n} M(x) \Vert z(t) \Vert\]</span></p>
<p>where <span class="math inline">\(M(x)\)</span> decreases monotonically in <span class="math inline">\(x\)</span>. <strong>The rate of adaptation</strong> can
then be found by an application of the chain rule <span class="math inline">\(\frac{d w(z)}{dt} = \frac{d w(z)}{d \Vert z(t) \Vert} \frac{d \Vert z(t) \Vert}{dt}\)</span>, i.e.</p>
<p><span class="math display">\[\frac{d w(t)}{dt} = \frac{2r^2}{n} M(x) w(t) \Vert z(t) \Vert^2\]</span></p>
<p>which can be written in terms of fitness exclusively by substituting <span class="math inline">\(\Vert z(t) \Vert^2 = -2 \log{w(t)}\)</span> (also in <span class="math inline">\(x\)</span>)</p>
<p><span class="math display">\[\frac{d w(t)}{dt} \approx - \frac{4r^2}{n} M(x) w(t) \log w(t) \]</span></p>
<p>Note that <span class="math inline">\(\log{w(t)} \le 0\)</span>, so that the rate of change in fitness is strictly
positive, i.e. under this model fitness can only increase. Also note how that
<span class="math inline">\(w(t) \log{w(t)}\)</span> term looks suspiciously like an entropy term (but note that
<span class="math inline">\(w(t)\)</span> is not a probability). The following plot illustrates these results for
various <span class="math inline">\(n\)</span> and mutation effect sizes <span class="math inline">\(r\)</span>:</p>
<figure>
<img src="../img/2021-01-01-fgm/dzdt.svg" style="width:100.0%" alt="Red dots indicate the maximum" />
<figcaption aria-hidden="true"><em>Red dots indicate the maximum</em></figcaption>
</figure>
<h2 id="the-optimal-mutation-and-the-cost-of-complexity">The optimal mutation and the cost of complexity</h2>
<p>Three important observations must be made:</p>
<ol type="1">
<li>The optimal mutation effect size <span class="math inline">\(r\)</span> (i.e. the <span class="math inline">\(r\)</span> leading to most rapid
adaptation) is intermediate.</li>
<li>The optimal <span class="math inline">\(r\)</span> decreases for increasing <span class="math inline">\(n\)</span>.</li>
<li>The maximal and average (over <span class="math inline">\(r\)</span>) rate of adaptation decreases with increasing <span class="math inline">\(n\)</span>.</li>
</ol>
<p>The first point is a qualitative feature independent of the dimensionality <span class="math inline">\(n\)</span>
of the space. It is a straightforward consequence of combining FGM with the
population genetics of selection, which Orr attributes to Kimura. While
mutations of large effect have smaller probabilities of being advantageous
(FGM), they are more likely to fix in the population when advantageous
(popgen). Or, stated the other way around, mutations of small effect may be
more likely to be adaptive, they are more likely to get lost due to genetic
drift at the same time. The combination of FGM with the population genetics
of selection in finite populations leads to a model which provides a quite
elegant refutation of the micromutationist stance that is sometimes associated
with a particular hardcore brand of neo-Darwinism.</p>
<p>The ‘cost of complexity’ as proclaimed in the title of Orr’s paper however
emerges when we consider the effect of <span class="math inline">\(n\)</span>, the dimensionality of the
phenotypic space. First recall that in the model, <span class="math inline">\(n\)</span> is properly interpreted
as the number of orthogonal traits under stabilizing selection for a given
constant optimum, and that the assumption of <em>universal pleiotropy</em> entails
that any mutation affects <em>all</em> <span class="math inline">\(n\)</span> idealized traits almost surely. As we
increase the number of phenotypic dimensions relevant for adaptation, we see
that the rate of adaptation for a given <span class="math inline">\(r\)</span> and current distance <span class="math inline">\(\Vert z \Vert\)</span> from the
optimum decreases markedly. This phenomenon is referred to as the cost of
complexity. More complex organisms (on this interpretation) adapt more slowly.</p>
<p>The cost of complexity has three sources</p>
<ol type="1">
<li>The probability of a mutation being advantageous for a given effect size <span class="math inline">\(r\)</span>
decreases with <span class="math inline">\(n\)</span> (Fisher)</li>
<li>The expected phenotypic change of a favorable mutation decreases with <span class="math inline">\(n\)</span>
(a consequence of (1))</li>
<li>The expected phenotypic change for a fixed mutation decreases with <span class="math inline">\(n\)</span></li>
</ol>
<p>while the latter two aspects are consequences of the first, they enter the
final expression for the rate of fitness increase during adaptation
independently. As Orr notes, Fisher’s basic observations hold, but the cost of
complexity is considerably higher than Fisher’s analysis suggests if we
take into account the population genetics of selection in finite populations.</p>
<h2 id="some-remarks-about-fgm">Some remarks about FGM</h2>
<blockquote>
<p>“The purpose of models is not to fit the data but to sharpen the question.” –
Samuel Karlin</p>
</blockquote>
<h3 id="orrs-effective-number-of-dimensions">Orr’s effective number of dimensions</h3>
<p>A curious result that follows from Orr’s model, is that while the optimal <span class="math inline">\(r\)</span>
decreases for increasing <span class="math inline">\(\sqrt n\)</span>, on the standardized scale determined by
<span class="math inline">\(x = r\sqrt{n}/2z\)</span>, the optimal mutation size <span class="math inline">\(x_\mathrm{opt}\)</span> is a constant
approximately equal to 0.95.</p>
<p>This entails that if we could locate the mutation effect size that maximizes
the change in fitness in some situation, we could use the FGM predictions to
estimate the <span class="math inline">\(n\)</span> under the assumptions of FGM. We could than consider this
<span class="math inline">\(n_e\)</span> a kind of ‘effective number’ of phenotypic dimensions <em>under selection</em>,
much like effective population size is defined with respect to some idealized
population. Clearly this is more of a thought experiment than a truly useful
result. But the idea is clear and potentially useful, if we would have more
easily measurable properties of FGM we might be able to meaningfully estimate a
thing like <span class="math inline">\(n_e\)</span>. This would turn a model that is of course manifestly wrong in
many ways into a model that could bring insights into the complexity of the
genotype-phenotype map underlying some trait, much like the effective
population size in population genetics captures key features of the
reproductive dynamics of a population.</p>
<h3 id="further">Further</h3>
<ul>
<li>Robustness results of Welch &amp; Waxman <span class="citation" data-cites="welch2003">[@welch2003]</span>.</li>
<li>Comparing across different <span class="math inline">\(n\)</span>: While FGM is an altogether extremely gross
simplification of phenotypic evolution (universal pleiotropy, a single
optimum, frequency independence, etc. etc. <em>ad infinitum</em>), a notion
completely lacking from the model which I find interesting is the possibility
of mutations that increase or decrease complexity. This gets of course
directly to the core of the issue with FGM and Orr’s analysis, are we sure
our comparisons across different <span class="math inline">\(n\)</span> are even meaningful? What, for instance,
if the optimum in dimension <span class="math inline">\(n\)</span> corresponds to a lower absolute fitness then
the optimum in dimension <span class="math inline">\(n+1\)</span>? Or, given the cost of complexity, it seems
natural to assume that a complexity decreasing mutation (that preserves
functionality) can invade a population, all else being equal.</li>
</ul>
<p><em>Last updated: January 2021</em></p>
    </section>
</article>

        </main>

        <footer>
            Site generated using 
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
            <br><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                <img alt="Creative Commons License" style="border-width:0;opacity:0.5;width:80px;" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a></a>
        </footer>
    </body>
        <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
</html>
